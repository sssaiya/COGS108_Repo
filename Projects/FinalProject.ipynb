{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Customer reviews are very important to the shopping experience in online retail. Shoppers on Amazon, EBay, Yelp,\n",
    "and other major online retailers rely on customer reviews heavily before buying a product. For our project, we wanted to focus on reviews from Amazon.com and analyze them to figure out how, for a product, language used in the review and the overall rating given relate to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Susmitha Kalidindi \n",
    "- Alyssa Ashmore \n",
    "- Shardul Saiya \n",
    "- Siyi Wang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members IDs\n",
    "\n",
    "- A13167684\n",
    "- A12833150\n",
    "- A13964199\n",
    "- A53233349"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to study the correlation is between words used in product reviews with the ratings given for that\n",
    "product by mapping the keywords in Amazon review text against the review ratings to see if words can be used to predict ratings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we give positive reviews we tend to say “Very good product” or “Strongly Recommended” and the reviews will tend to have higher ratings. On the other hand, certain words like “Broken” or “Slow” will tend to have correlation with lower ratings for the review. We expect to see similar correspondence in our data, and we would like to explore the relation between emotions and language in a very simple way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online retailers such as Amazon have been littered with fake reviews recently, and this problem appears to be only getting worse with time. ReviewMeta, a website that analyzes millions of reviews and deletes suspicious reviews from their analysis, explains in their article (Reference 1) that there is a growing problem of “fake” reviews. For instance, ReviewMeta states that in the first three months of 2019, there are 42% of “Verified Purchases” and 58% of “Unverified Purchases,” compared to 2018, where there were 91% verified purchases and 9% unverified purchases. On top of that, these unverified purchases are often overwhelmingly positive compared to verified purchases, which could indicate reviews that are fake or paid for by companies trying to falsely promote their product. \n",
    "\n",
    "That being said, more analysis about the extent of this problem is necessary in order to provide more accurate product reviews for users. Where our data solution comes in when tackling this issue is analyzing the correlation between a reviewer’s word usage and their specific rating. We would like to then inquire about the relationship between fake or incentivized reviews and the reviewer’s word usage and specific ratings. Finally, we can use these findings to better discover suspicious or incentivized reviews and provide more accurate reviews to consumers.\n",
    "\n",
    "Similar studies that have tackled this issue were done by researchers Mohan Kamal Hassan, Sana Prasanth Shakthi and R Sasikala in the paper “Sentimental analysis of Amazon reviews using naïve bayes on laptop products with MongoDB and R” (Reference 2). In this paper, they presented “an empirical study of efficacy of classifying product review by tagging the keyword . . . [and using] product users review comments about product and review about retailers from Amazon as data set and classify review text by subjectivity/objectivity and negative/positive attitude of buyer.” \n",
    "\n",
    "Additionally, students at Stanford University analyzed “the correlation between the Amazon product reviews and the rating of the products given by the customers” in their project using various techniques to find the most accurate one. They found that LSTM networks provided the most accurate correlation. \n",
    "\n",
    "References:\n",
    "(1) \"Amazon Flooded with Millions of Fake Reviews in 2019.\" ReviewMeta.\n",
    "https://reviewmeta.com/blog/amazon-flooded-with-millions-of-fake-reviews-in-2019/\n",
    "\n",
    "(2) \"Sentimental analysis of Amazon reviews using naïve bayes on laptop products with MongoDB and R.\" Mohan Kamal Hassan et al 2017 IOP Conf. Ser.: Mater. Sci. Eng. 263 042090. \n",
    "https://www.researchgate.net/publication/321479545_Sentimental_analysis_of_Amazon_reviews_using_naive_bayes_on_laptop_products_with_MongoDB_and_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Name: Consumer Reviews of Amazon Products\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products#Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\n",
    "\n",
    "Number of observations: 34,000 reviews\n",
    "\n",
    "This dataset contains a list of over 34,000 reviews of Amazon products like the Kindle, Fire TV, including measures on the basic product information, rating, review text, and more for each product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Review prediction without NLP\n",
    "\n",
    "The first step that we took in our project was to explore and visualize the raw text reviews and ratings to get a better understanding and sense of the data.\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import Data from CSV file here, SEE Project proposal for link to csv file\n",
    "import pandas as pd \n",
    "\n",
    "dfraw = pd.read_csv(\"../consumer-reviews-of-amazon-products/1429_1.csv\", engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Raw Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x107284c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,20))\n",
    "ax1 = plt.subplot2grid((4, 2), (0, 0))\n",
    "ax2 = plt.subplot2grid((4, 2), (1, 0))\n",
    "ax3 = plt.subplot2grid((4, 2), (0, 1), rowspan=2)\n",
    "\n",
    "rating_hist = dfraw.groupby('reviews.rating', as_index = False).count()\n",
    "sns.barplot(x = rating_hist['reviews.rating'].values, y = rating_hist['id'].values, ax = ax1)\n",
    "\n",
    "helpful_hist = dfraw.groupby('reviews.numHelpful', as_index = False).count()[0:30]\n",
    "sns.barplot(x = helpful_hist['reviews.numHelpful'].values.astype(int), y = helpful_hist['id'].values, ax = ax2)\n",
    "\n",
    "category_hist = dfraw.groupby('categories', as_index = False).count()\n",
    "sns.barplot(x  =category_hist['categories'].index, y = category_hist['id'].values)\n",
    "\n",
    "ax1.set_title(\"Reviews Ratings\", fontsize = 12)\n",
    "ax2.set_title(\"Helpful Feedback\", fontsize = 12)\n",
    "ax3.set_title(\"Categories\", fontsize = 12)\n",
    "\n",
    "# plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During data cleaning, we got rid of the useless rows for our dataset. Then, we replaced hard to read characters in the review text with spaces to make our data analysis more efficient and easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of most unwanted rows, only keep \n",
    "# Name, Category, Reviews.DoRecommend, Review.numHelpful, Reviews.ratings, Review.text, Review.title \n",
    "\n",
    "df1 = dfraw.drop(['asins', 'brand', 'keys', 'manufacturer', 'reviews.sourceURLs', 'reviews.userCity', \n",
    "                  'reviews.userProvince', 'reviews.username', 'reviews.dateAdded', 'reviews.dateSeen', \n",
    "                  'reviews.didPurchase' , 'reviews.id', 'id' ], axis=1)\n",
    "\n",
    "#get rid of rewiews without ratings\n",
    "df1 = df1.dropna(subset=['reviews.rating', 'reviews.text', 'reviews.text'])\n",
    "\n",
    "# Now df1 contains:\n",
    "# name, categories, reviews.date, reviews.doRecommend,\n",
    "# reviews.numHelpful, reviews.rating, reviews.text, reviews.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function to filter data\n",
    "def filter_review(review):\n",
    "    # Convert to string\n",
    "    string = str(review)\n",
    "    \n",
    "    # Data Filtering\n",
    "    string = string.replace('.', ' ')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    # string = string.replace('\\'', ' ')\n",
    "    string = string.replace('\\\"', ' ')\n",
    "    string = string.replace('/', ' ')\n",
    "    string = string.replace('(', ' ')\n",
    "    string = string.replace(')', ' ')\n",
    "    string = string.replace('!', ' ')\n",
    "    string = string.replace('?', ' ')\n",
    "    string = string.replace('=', ' ')\n",
    "    string = string.replace('+', ' ')\n",
    "    string = string.replace('-', ' ')\n",
    "    string = string.replace('�', '')\n",
    "    string = string.replace('☺️', ' ')\n",
    "    string = string.replace('&', ' ')\n",
    "    string = string.replace('$', ' ')\n",
    "    string = string.replace('*', ' ')\n",
    "    string = string.replace('%', ' ')\n",
    "\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>Kindle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>very fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>Beginner tablet for our 9 year old son.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>Good!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>2017-01-12T00:00:00.000Z</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>Fantastic Tablet for kids</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "1  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "2  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "3  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "4  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "2  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "3  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "4  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "\n",
       "               reviews.date reviews.doRecommend  reviews.numHelpful  \\\n",
       "0  2017-01-13T00:00:00.000Z                True                 0.0   \n",
       "1  2017-01-13T00:00:00.000Z                True                 0.0   \n",
       "2  2017-01-13T00:00:00.000Z                True                 0.0   \n",
       "3  2017-01-13T00:00:00.000Z                True                 0.0   \n",
       "4  2017-01-12T00:00:00.000Z                True                 0.0   \n",
       "\n",
       "   reviews.rating                                       reviews.text  \\\n",
       "0             5.0  This product so far has not disappointed. My c...   \n",
       "1             5.0  great for beginner or experienced person. Boug...   \n",
       "2             5.0  Inexpensive tablet for him to use and learn on...   \n",
       "3             4.0  I've had my Fire HD 8 two weeks now and I love...   \n",
       "4             5.0  I bought this for my grand daughter when she c...   \n",
       "\n",
       "                             reviews.title  \n",
       "0                                   Kindle  \n",
       "1                                very fast  \n",
       "2  Beginner tablet for our 9 year old son.  \n",
       "3                                  Good!!!  \n",
       "4                Fantastic Tablet for kids  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary to count all unique words in customer reviews\n",
    "# contains word : frequency\n",
    "words_dict = {}\n",
    "\n",
    "# Helper function to count words in a string \n",
    "# This function directly modifies the words_dict declared above\n",
    "def word_frequency_counter(review):\n",
    "    \n",
    "    string = filter_review(review)\n",
    "\n",
    "    # Convert to lower case and split\n",
    "    my_string = string.lower().split()\n",
    "    for item in my_string:\n",
    "        if item in words_dict:\n",
    "            words_dict[item] += 1\n",
    "        else:\n",
    "            words_dict[item] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary to count raw rating value of each word\n",
    "rating_dict = {}\n",
    "\n",
    "#Helper function to add up raw review values for each word and \n",
    "def rating_counter(review, rating):\n",
    "    string = filter_review(review)\n",
    "    rating = int(rating)\n",
    "    \n",
    "    # Convert to lower case and split\n",
    "    my_string = string.lower().split()\n",
    "    for item in my_string:\n",
    "        if item in rating_dict:\n",
    "            rating_dict[item] = rating_dict[item] + rating\n",
    "        else:\n",
    "            rating_dict[item] = rating\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for review in df1['reviews.text']:\n",
    "    word_frequency_counter(review)\n",
    "for index, row in df1.iterrows():\n",
    "    rating_counter(row['reviews.text'], row['reviews.rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x107574a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize word frequency's for top words with a histogram or some other graph\n",
    "sorted_words_list = list(sorted(words_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "words_list_20 = sorted_words_list[0:20] \n",
    "df_words = pd.DataFrame(words_list_20, columns=['word', 'frequency'])\n",
    "df_words.plot(kind='bar', x='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susmitha/anaconda2/lib/python2.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x107df4a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import copy\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sorted_words_list = list(sorted(words_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_words_list_nonneutral = copy.deepcopy(sorted_words_list)\n",
    "\n",
    "for item in sorted_words_list:\n",
    "    ss = sid.polarity_scores(item[0])\n",
    "    # if word is neutral, then don't include it in this graph\n",
    "    # we only care about positive/negative words\n",
    "    if ss['neu'] == 1.0:\n",
    "        sorted_words_list_nonneutral.remove(item)\n",
    "\n",
    "\n",
    "words_list_20_nonneutral = sorted_words_list_nonneutral[0:20] \n",
    "df_words_nonneutral = pd.DataFrame(words_list_20_nonneutral, columns=['word', 'frequency'])\n",
    "df_words_nonneutral.plot(kind='bar', x='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have two dictionaries\n",
    "# word_dict contains words associated with their frequency in all the ratings\n",
    "# rating_dict_raw cotains words associated with their raw rating values, summed up\n",
    "\n",
    "\n",
    "# Now we want to divide the values in rating_dict by the frequency values in word_dict\n",
    "# Thats what this helper function does, and saves it in rating_dict\n",
    "def ratings_avg(word_dict, rating_dict):\n",
    "    for item in word_dict:\n",
    "        if item in rating_dict:\n",
    "            rating_dict[item] = rating_dict[item]/word_dict[item]\n",
    "        else:\n",
    "            print('This shouldnt happen !!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_avg(words_dict, rating_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Visualize these average rating values with words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem with the Above Approach \n",
    "The naive way of simply counting how many times each word appears in every document is that it doesn’t take into account the relative importance of words in the texts. \n",
    "A word that appears in almost every text would not likely bring useful information for analysis. For example, words like \"the\", \"and\", \"in\" may be extremely common words used in reviews but they don't provide any insight into understanding the polarity of reviews.\n",
    "On the contrary, rare words may have a lot more of meanings.\n",
    "\n",
    "# Hence the motivation for Part 2...\n",
    "\n",
    "### We add the TF-IDF (Term Frequency — Inverse Document Frequency) values for every word and every document.\n",
    "The TF-IDF metric solves this problem:\n",
    "\n",
    "- TF computes the classic number of times the word appears in the text\n",
    "- IDF computes the relative importance of this word which depends on how many texts the word can be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "## Detecting Bad customer reviews with NLP\n",
    "\n",
    "For each textual review, we want to predict if it corresponds to a good review (the customer is happy) or to a bad one (the customer is not satisfied). The reviews overall ratings can range from 0/5 to 5/5. \n",
    "\n",
    "We will split those into two categories:\n",
    "\n",
    "bad reviews have overall ratings < 2.5\n",
    "good reviews have overall ratings >= 2.5\n",
    "\n",
    "Then we see if we are be able to predict this information using only the raw textual data from the review. Let’s get it started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = dfraw.drop(['asins', 'brand', 'keys', 'manufacturer', 'reviews.sourceURLs', 'reviews.userCity', \n",
    "                  'reviews.userProvince', 'reviews.username', 'reviews.dateAdded', 'reviews.dateSeen', \n",
    "                  'reviews.didPurchase' , 'reviews.id', 'id' ], axis=1)\n",
    "reviews_df = df2.drop(['name','reviews.date', 'categories'], axis=1)\n",
    "\n",
    "# create the label\n",
    "reviews_df[\"is_bad_review\"] = reviews_df[\"reviews.rating\"].apply(lambda x: 1 if x <= 3 else 0)\n",
    "# select only relevant columns\n",
    "reviews_df = reviews_df[[\"reviews.text\", \"is_bad_review\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>is_bad_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  is_bad_review\n",
       "0  This product so far has not disappointed. My c...              0\n",
       "1  great for beginner or experienced person. Boug...              0\n",
       "2  Inexpensive tablet for him to use and learn on...              0\n",
       "3  I've had my Fire HD 8 two weeks now and I love...              0\n",
       "4  I bought this for my grand daughter when she c...              0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what our data now looks like\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample the data to speed up computation,\n",
    "# uncomment is data is taking too long but shouldnt be necessary\n",
    "reviews_df = reviews_df.sample(frac = 0.1, replace = False, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/susmitha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/susmitha/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the wordnet object value corresponding to the POS tag\n",
    "import nltk \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning Using NLTK\n",
    "### clean_text Does the following things:\n",
    "- lower case the text\n",
    "- tokenize the text \n",
    "- remove punctuation\n",
    "- remove useless words that contain numbers\n",
    "- remove useless stop words like ‘the’, ‘a’ ,’this’ etc.\n",
    "- Part-Of-Speech (POS) tagging: assign a tag to every word to define if it corresponds to a noun, a verb etc. using the WordNet lexical database\n",
    "- lemmatize the text: transform every word into their root form (e.g. rooms -> room, slept -> sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # float/int etc to string\n",
    "    text = str(text)\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    return(text)\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susmitha/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-db56ce192195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review_clean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reviews.text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreviews_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/susmitha/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-db56ce192195>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review_clean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reviews.text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreviews_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-4df4d3fa15c6>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# lemmatize text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# remove words with only one letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/susmitha/anaconda2/lib/python2.7/site-packages/nltk/stem/wordnet.pyc\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/susmitha/anaconda2/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.pyc\u001b[0m in \u001b[0;36m_morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m         \u001b[0;31m# 1. Apply rules once to the input to get y1, y2, y3, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m         \u001b[0mforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;31m# 2. Return all that are in the database (and check the original too)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/susmitha/anaconda2/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.pyc\u001b[0m in \u001b[0;36mapply_rules\u001b[0;34m(forms)\u001b[0m\n\u001b[1;32m   1773\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubstitutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m                     if form.endswith(old)]\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfilter_forms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "reviews_df[\"review_clean\"] = reviews_df[\"reviews.text\"].apply(lambda x: clean_text(x))\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "We use Vader, which is a part of the NLTK module designed for sentiment analysis. \n",
    "Vader uses a lexicon of words to find which ones are positives or negatives. \n",
    "It also takes into account the context of the sentences to determine the sentiment scores. \n",
    "For each text, Vader returns 4 values:\n",
    "- Negativity score (neg)\n",
    "- Neutrality score (neu)\n",
    "- Positivity score (pos)\n",
    "- Overall score (compound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add sentiment anaylsis columns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "reviews_df[\"sentiments\"] = reviews_df[\"reviews.text\"].apply(lambda x: sid.polarity_scores(x))\n",
    "reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we find simple metrics for every text which we will use ahead :\n",
    "- Number of characters in each review\n",
    "- Number of words in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add number of characters column\n",
    "reviews_df[\"nb_chars\"] = reviews_df[\"reviews.text\"].apply(lambda x: len(x))\n",
    "\n",
    "# add number of words column\n",
    "reviews_df[\"nb_words\"] = reviews_df[\"reviews.text\"].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step consist in extracting vector representations for every review. \n",
    "The module Gensim creates a numerical vector representation of every word in the corpus by using the contexts in which they appear (Word2Vec). \n",
    "This is performed using shallow neural networks. What’s interesting is that similar words will have similar representation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create doc2vec vector columns\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews_df[\"review_clean\"].apply(lambda x: x.split(\" \")))]\n",
    "\n",
    "# train a Doc2Vec model with our text data\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "# transform each document into a vector data\n",
    "doc2vec_df = reviews_df[\"review_clean\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n",
    "reviews_df = pd.concat([reviews_df, doc2vec_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to train a Doc2Vec model by feeding in our text data. By applying this model on our reviews, we can get those representation vectors.\n",
    "\n",
    "We add TF-IDF columns for every word that appear in at least 10 different texts to filter some of them and reduce the size of the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df = 10)\n",
    "tfidf_result = tfidf.fit_transform(reviews_df[\"review_clean\"]).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "tfidf_df.index = reviews_df.index\n",
    "reviews_df = pd.concat([reviews_df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_df[\"is_bad_review\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you may have noticed, about 6 percent of our reviews are considered negative ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud of data after filtering and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wordcloud function\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 200,\n",
    "        max_font_size = 40, \n",
    "        scale = 3,\n",
    "        random_state = 42\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize = (20, 20))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "    \n",
    "# print wordcloud\n",
    "show_wordcloud(reviews_df[\"reviews.text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# highest positive sentiment reviews (with more than 5 words)\n",
    "reviews_df[reviews_df[\"nb_words\"] >= 5].sort_values(\"pos\", ascending = False)[[\"reviews.text\", \"pos\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lowest negative sentiment reviews (with more than 5 words)\n",
    "reviews_df[reviews_df[\"nb_words\"] >= 5].sort_values(\"neg\", ascending = False)[[\"reviews.text\", \"neg\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot sentiment distribution for positive and negative reviews\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "for x in [0, 1]:\n",
    "    subset = reviews_df[reviews_df['is_bad_review'] == x]\n",
    "    \n",
    "    # Draw the density plot\n",
    "    if x == 0:\n",
    "        label = \"Good reviews\"\n",
    "    else:\n",
    "        label = \"Bad reviews\"\n",
    "    sns.distplot(subset['compound'], hist = False, label = label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting is_bad_review\n",
    "\n",
    "\n",
    "We first choose which features we want to use to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "label = \"is_bad_review\"\n",
    "ignore_cols = [label, \"reviews.text\", \"review_clean\"]\n",
    "features = [c for c in reviews_df.columns if c not in ignore_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data into two parts:\n",
    "- one to train our model\n",
    "- one to test its performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_df[features], \n",
    "                                        reviews_df[label], test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Important Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show feature importance\n",
    "feature_importances_df = pd.DataFrame({\"feature\": features, \"importance\": rf.feature_importances_}).sort_values(\"importance\", ascending = False)\n",
    "feature_importances_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most important features are indeed the ones that come from the previous sentiment analysis.\n",
    "ie - compound, pos, neu.\n",
    "\n",
    "- The vector representations of the texts also have a lot of importance in our training. \n",
    "- Some words appear to have a fairly good importance as well.\n",
    "\n",
    "\n",
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = [x[1] for x in rf.predict_proba(X_test)]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label = 1)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(1, figsize = (15, 10))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC isnt a good predictor here\n",
    "Why?\n",
    "(False Positive Rate) = # False Positives / # Negatives.\n",
    "\n",
    "Here the # Negatives corresponds to our number of good reviews which is very high because our dataset is imbalanced. This means that even with some False Positives, our FPR will tend to stay very low. Our model will be able to make a lot of false positives predictions and still have a low false positive rate, while increasing the true positive rate and therefore artificially increasing the AUC ROC metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PR curve\n",
    "\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "\n",
    "plt.figure(1, figsize = (15, 10))\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the precision decreases when we increase the recall. \n",
    "\n",
    "- If our goal is to have a high recall, we should set a low prediction thresold that will allow us to detect most of the observations of the positive class, but with a low precision. \n",
    "- On the contrary, if we want to be really confident about our predictions but don’t mind about not finding all the positive observations, we should set a high thresold that will get us a high precision and a low recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy/Ethics Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand what our ethical and privacy concerns may be in answering this data science question, we looked into Amazon’s privacy policy on using user review data for data analysis. One section of Amazon’s Privacy notice states that “Information You Give Us: We receive and store any information you enter on our Web site or give us in any other way. You can choose not to provide certain information, but then you might not be able to take advantage of many of our features. We use the information that you provide for such purposes as responding to your requests, customizing future shopping for you, improving our stores, and communicating with you.” \n",
    "\n",
    "Thus, as part of amazon’s policy, users agree for some parts of their data to be public information to take advantage of features like customer reviews and personalized shopping. For our data science project, we are only using their reviews and ratings of which they have already voluntarily partook in. Hence, we don’t have any privacy concerns by using our dataset. Additionally, Amazon provides the customer reviews dataset on AWS.\n",
    "\n",
    "Additionally, we also don’t have any ethical concerns as Amazon’s data is already filtered to remove offensive terms and phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Discuss your project. Summarize your data and question. Briefly describe your analysis. Summarize your results and conclusions. Be sure to mention any limitations of your project. Discuss the impact of this work on society. (2-3 paragraphs)\n",
    "\n",
    "To reiterate our goal for this project, \n",
    "\n",
    "\n",
    "One limitation of this project is that it only includes consumer reviews of Amazon products only, such as Kindle, Kindle Fire, etc, so we are not analyzing an incredible variety of products. It's likely that the polarity of the reviews is slightly skewed because of this; as we saw from the data, only 6% of the reviews were negative. Also as mentioned earlier in the introduction, we can expect there to be some level of fake reviews for these products that affects the dataset. It would take additional data sanitization to remove these fake reviews to ensure higher quality data; however we were not able to do this given the time constraints.  \n",
    "\n",
    "We wanted to see how language and emotions related to each other by analyzing reviews. This project is impactful since we learned that commonly used words don't offer indication to any specific emotion since these tend to be idiosyncratic words like \"the\", \"in\", \"of.\" It's better to analyze infrequent words, such as \"broken\" or \"failed\" in a review since they might offer more of a insight into a specific sentiment. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
